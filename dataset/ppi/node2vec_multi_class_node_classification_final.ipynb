{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import stellargraph as sg\n",
    "from stellargraph.data import EdgeSplitter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \n",
    "#from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = json_graph.node_link_graph(json.load(open(\"ppi-G.json\")))\n",
    "edges = [n for n in G.edges()]\n",
    "ppi_edge_file = \"ppi_edge_list.txt\"\n",
    "with open(ppi_edge_file, 'w') as fp:\n",
    "    fp.write('\\n'.join('{} {}'.format(x[0],x[1]) for x in edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = json.load(open(\"ppi-class_map.json\"))\n",
    "n = len(class_map.keys())\n",
    "m = len(class_map['0'])\n",
    "target = np.zeros((n,m))\n",
    "for i in range(n):\n",
    "    target[i] = np.array(class_map[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels_internal = json.load(open(\"ppi-class_map.json\"))\n",
    "edge_labels_internal = {int(i): l for i, l in edge_labels_internal.items()}\n",
    "train_ids = [n for n in G.nodes()]\n",
    "train_labels = np.array([edge_labels_internal[i] for i in train_ids])\n",
    "if train_labels.ndim == 1:\n",
    "    train_labels = np.expand_dims(train_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"tmp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_10_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b2c494c3740debdc1253c622c592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [28:32<00:00, 856.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  67%|██████▋   | 2/3 [28:39<14:19, 859.75s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [52:32<00:00, 1576.10s/it][A\u001b[A\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [52:35<00:00, 1577.74s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [52:38<00:00, 1033.42s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [52:37<00:00, 1033.20s/it]\u001b[A\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [1:00:13<00:00, 1204.39s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [1:00:15<00:00, 1205.31s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64, 128]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_100_10_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40615275e49413fb9b4707dbf7a624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [21:34<00:00, 647.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  67%|██████▋   | 2/3 [22:19<11:09, 669.73s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [42:05<00:00, 1262.80s/it][A\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [42:25<00:00, 1272.84s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [42:59<00:00, 840.69s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [53:58<00:00, 1079.42s/it][A\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [54:02<00:00, 1080.87s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [10,100]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_50_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aedb2451787470abae5fe699b666ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating walks (CPU: 1):   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating walks (CPU: 2):   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  15%|█▌        | 2/13 [11:52<1:05:15, 356.00s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  17%|█▋        | 2/12 [11:53<59:27, 356.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  15%|█▌        | 2/13 [11:57<1:05:43, 358.53s/it]A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  23%|██▎       | 3/13 [21:41<1:11:00, 426.05s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  25%|██▌       | 3/12 [21:44<1:04:03, 427.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  23%|██▎       | 3/13 [21:50<1:11:31, 429.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  31%|███       | 4/13 [33:43<1:17:12, 514.68s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  33%|███▎      | 4/12 [33:52<1:08:57, 517.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  31%|███       | 4/13 [34:14<1:18:30, 523.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  38%|███▊      | 5/13 [53:48<1:36:15, 721.92s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  42%|████▏     | 5/12 [54:00<1:24:30, 724.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  38%|███▊      | 5/13 [54:20<1:37:06, 728.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  46%|████▌     | 6/13 [1:42:24<2:41:00, 1380.06s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  50%|█████     | 6/12 [1:42:41<2:18:21, 1383.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  46%|████▌     | 6/13 [1:43:17<2:42:16, 1390.92s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  54%|█████▍    | 7/13 [2:04:02<2:15:32, 1355.39s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  58%|█████▊    | 7/12 [2:04:18<1:53:07, 1357.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  54%|█████▍    | 7/13 [2:04:52<2:16:12, 1362.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  62%|██████▏   | 8/13 [3:01:42<2:45:34, 1986.82s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  67%|██████▋   | 8/12 [3:02:07<2:12:43, 1990.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  62%|██████▏   | 8/13 [3:03:06<2:46:47, 2001.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  69%|██████▉   | 9/13 [3:48:18<2:28:39, 2229.76s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  75%|███████▌  | 9/12 [3:49:09<1:52:00, 2240.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  69%|██████▉   | 9/13 [3:51:47<2:31:50, 2277.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  77%|███████▋  | 10/13 [4:23:36<1:49:48, 2196.00s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  83%|████████▎ | 10/12 [4:23:51<1:13:05, 2192.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  77%|███████▋  | 10/13 [4:24:45<1:49:22, 2187.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  85%|████████▍ | 11/13 [5:15:55<1:22:38, 2479.13s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  92%|█████████▏| 11/12 [5:16:04<41:14, 2474.83s/it]  \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  85%|████████▍ | 11/13 [5:16:36<1:22:09, 2464.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  92%|█████████▏| 12/13 [5:25:26<31:46, 1906.58s/it]  \u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 12/12 [5:25:30<00:00, 1902.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 12/12 [5:29:44<00:00, 1648.70s/it]\n",
      "\n",
      "Generating walks (CPU: 2): 100%|██████████| 13/13 [5:29:44<00:00, 1412.17s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 2): 100%|██████████| 13/13 [5:31:32<00:00, 1530.19s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [50,100]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_10_40_0.2_1.emb\n",
      "ppi_node2vec_full_embeddings_64_10_40_1_1.emb\n",
      "ppi_node2vec_full_embeddings_64_10_40_2_1.emb\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [0.2, 2]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_10_40_1_0.2.emb\n",
      "ppi_node2vec_full_embeddings_64_10_40_1_1.emb\n",
      "ppi_node2vec_full_embeddings_64_10_40_1_2.emb\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [10]\n",
    "NUM_WALKS = [40]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [0.2, 2]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
