{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import stellargraph as sg\n",
    "from stellargraph.data import EdgeSplitter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \n",
    "#from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from node2vec import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = json_graph.node_link_graph(json.load(open(\"ppi-G.json\")))\n",
    "edges = [n for n in G.edges()]\n",
    "ppi_edge_file = \"ppi_edge_list.txt\"\n",
    "with open(ppi_edge_file, 'w') as fp:\n",
    "    fp.write('\\n'.join('{} {}'.format(x[0],x[1]) for x in edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = json.load(open(\"ppi-class_map.json\"))\n",
    "n = len(class_map.keys())\n",
    "m = len(class_map['0'])\n",
    "target = np.zeros((n,m))\n",
    "for i in range(n):\n",
    "    target[i] = np.array(class_map[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels_internal = json.load(open(\"ppi-class_map.json\"))\n",
    "edge_labels_internal = {int(i): l for i, l in edge_labels_internal.items()}\n",
    "train_ids = [n for n in G.nodes()]\n",
    "train_labels = np.array([edge_labels_internal[i] for i in train_ids])\n",
    "if train_labels.ndim == 1:\n",
    "    train_labels = np.expand_dims(train_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"tmp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_10_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b2c494c3740debdc1253c622c592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [28:32<00:00, 856.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  67%|██████▋   | 2/3 [28:39<14:19, 859.75s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [52:32<00:00, 1576.10s/it][A\u001b[A\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [52:35<00:00, 1577.74s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [52:38<00:00, 1033.42s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [52:37<00:00, 1033.20s/it]\u001b[A\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [1:00:13<00:00, 1204.39s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [1:00:15<00:00, 1205.31s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64, 128]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_100_10_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40615275e49413fb9b4707dbf7a624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [21:34<00:00, 647.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  67%|██████▋   | 2/3 [22:19<11:09, 669.73s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [42:05<00:00, 1262.80s/it][A\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [42:25<00:00, 1272.84s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [42:59<00:00, 840.69s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [53:58<00:00, 1079.42s/it][A\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [54:02<00:00, 1080.87s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [10,100]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_20_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08778d1fc2fe46afad0c82b3dc4603fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  40%|████      | 2/5 [08:28<12:43, 254.39s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  40%|████      | 2/5 [08:32<12:49, 256.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  40%|████      | 2/5 [08:36<12:54, 258.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  60%|██████    | 3/5 [16:34<10:47, 323.80s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  60%|██████    | 3/5 [16:43<10:53, 326.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  60%|██████    | 3/5 [16:51<10:58, 329.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  80%|████████  | 4/5 [24:38<06:11, 371.82s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  80%|████████  | 4/5 [24:52<06:15, 375.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 4/5 [25:05<06:18, 378.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2): 100%|██████████| 5/5 [33:23<00:00, 417.77s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 5/5 [33:43<00:00, 422.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [34:03<00:00, 426.31s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                                                \n",
      "\n",
      "Generating walks (CPU: 2): 100%|██████████| 5/5 [41:28<00:00, 497.63s/it]\n",
      "\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 5/5 [41:45<00:00, 501.17s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 5/5 [41:46<00:00, 501.31s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 5/5 [41:50<00:00, 502.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_50_1_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfd30be2294426a8d4a8ead9bdfef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  17%|█▋        | 2/12 [08:11<40:57, 245.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  17%|█▋        | 2/12 [08:11<40:58, 245.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  15%|█▌        | 2/13 [08:19<45:47, 249.80s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  25%|██▌       | 3/12 [17:09<50:02, 333.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  25%|██▌       | 3/12 [17:09<50:02, 333.58s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  23%|██▎       | 3/13 [17:30<56:39, 340.00s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  33%|███▎      | 4/12 [25:24<50:54, 381.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  33%|███▎      | 4/12 [25:24<50:55, 381.90s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  31%|███       | 4/13 [25:49<58:11, 387.89s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  42%|████▏     | 5/12 [33:31<48:13, 413.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  42%|████▏     | 5/12 [33:31<48:14, 413.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  38%|███▊      | 5/13 [34:06<56:04, 420.61s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  50%|█████     | 6/12 [42:39<45:22, 453.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  50%|█████     | 6/12 [42:39<45:22, 453.72s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  46%|████▌     | 6/13 [43:23<53:50, 461.50s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  58%|█████▊    | 7/12 [50:44<38:36, 463.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  58%|█████▊    | 7/12 [50:45<38:37, 463.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  54%|█████▍    | 7/13 [51:39<47:11, 471.90s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  67%|██████▋   | 8/12 [1:00:39<33:30, 502.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  67%|██████▋   | 8/12 [1:00:40<33:31, 502.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  62%|██████▏   | 8/13 [1:02:06<43:12, 518.44s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  75%|███████▌  | 9/12 [1:11:15<27:08, 542.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  75%|███████▌  | 9/12 [1:11:16<27:08, 542.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  69%|██████▉   | 9/13 [1:12:32<36:42, 550.51s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  83%|████████▎ | 10/12 [1:19:47<17:47, 533.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  83%|████████▎ | 10/12 [1:19:48<17:46, 533.42s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  77%|███████▋  | 10/13 [1:21:16<27:08, 542.73s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  92%|█████████▏| 11/12 [1:28:15<08:45, 525.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  92%|█████████▏| 11/12 [1:28:17<08:46, 526.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  85%|████████▍ | 11/13 [1:30:06<17:57, 538.75s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 12/12 [1:36:38<00:00, 518.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 12/12 [1:36:40<00:00, 519.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  92%|█████████▏| 12/13 [1:38:30<08:48, 528.58s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 12/12 [1:46:39<00:00, 533.32s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 12/12 [1:46:41<00:00, 533.46s/it]\n",
      "\n",
      "Generating walks (CPU: 1): 100%|██████████| 13/13 [1:47:30<00:00, 531.93s/it]\u001b[A\n",
      "Generating walks (CPU: 1): 100%|██████████| 13/13 [1:50:38<00:00, 510.62s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 13/13 [1:51:04<00:00, 512.68s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [20,50]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_10_0.2_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd9096bc8544ebbac3d8a582de78363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [09:22<00:00, 281.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  67%|██████▋   | 2/3 [09:29<04:44, 284.92s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [18:39<00:00, 559.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [18:54<00:00, 567.30s/it]\u001b[A\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [22:43<00:00, 454.56s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [22:45<00:00, 455.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_40_10_2_1.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db45a0ffd3974995a3c278739b6956b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 3):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [10:32<00:00, 316.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  67%|██████▋   | 2/3 [10:33<05:16, 316.73s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [21:08<00:00, 634.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [21:10<00:00, 635.00s/it]\u001b[A\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [21:15<00:00, 415.08s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [25:17<00:00, 505.95s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [25:53<00:00, 517.86s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [0.2, 2]\n",
    "Qs = [1]\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_10_40_1_0.2.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1590f3d74a44afb120b6b83e12dde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  20%|██        | 2/10 [02:13<08:53, 66.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  20%|██        | 2/10 [02:14<08:58, 67.25s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  20%|██        | 2/10 [02:16<09:07, 68.42s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  30%|███       | 3/10 [04:11<09:34, 82.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  30%|███       | 3/10 [04:13<09:39, 82.73s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  30%|███       | 3/10 [04:18<09:49, 84.26s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  40%|████      | 4/10 [06:25<09:46, 97.74s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  40%|████      | 4/10 [06:28<09:50, 98.44s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  40%|████      | 4/10 [06:35<10:01, 100.28s/it][A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  50%|█████     | 5/10 [08:21<08:35, 103.18s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  50%|█████     | 5/10 [08:24<08:39, 103.81s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  50%|█████     | 5/10 [08:33<08:47, 105.49s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  60%|██████    | 6/10 [10:36<07:30, 112.59s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  60%|██████    | 6/10 [10:41<07:34, 113.53s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  60%|██████    | 6/10 [10:52<07:41, 115.44s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  70%|███████   | 7/10 [12:34<05:43, 114.42s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  70%|███████   | 7/10 [12:40<05:45, 115.18s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  70%|███████   | 7/10 [12:52<05:51, 117.02s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  80%|████████  | 8/10 [14:26<03:47, 113.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  80%|████████  | 8/10 [14:33<03:49, 114.55s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  80%|████████  | 8/10 [14:47<03:52, 116.47s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  90%|█████████ | 9/10 [16:42<02:00, 120.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):  90%|█████████ | 9/10 [16:51<02:01, 121.55s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 1):  90%|█████████ | 9/10 [17:09<02:03, 123.92s/it]\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 10/10 [18:37<00:00, 118.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3): 100%|██████████| 10/10 [18:46<00:00, 119.84s/it]\u001b[A\u001b[A\n",
      "Generating walks (CPU: 4): 100%|██████████| 10/10 [20:29<00:00, 122.91s/it]\u001b[A\n",
      "Generating walks (CPU: 3): 100%|██████████| 10/10 [20:36<00:00, 123.60s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 10/10 [20:44<00:00, 124.41s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [20:45<00:00, 124.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppi_node2vec_full_embeddings_64_10_40_1_2.emb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a131fed0f24fe4a899a9f62ebab014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Computing transition probabilities', max=56944, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 3):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4):   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  20%|██        | 2/10 [01:53<07:32, 56.53s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  20%|██        | 2/10 [01:55<07:40, 57.54s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  20%|██        | 2/10 [01:56<07:44, 58.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  30%|███       | 3/10 [03:45<08:32, 73.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  30%|███       | 3/10 [03:48<08:40, 74.37s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  30%|███       | 3/10 [03:50<08:44, 74.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  40%|████      | 4/10 [05:59<09:09, 91.60s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  40%|████      | 4/10 [06:05<09:17, 92.98s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  40%|████      | 4/10 [06:08<09:22, 93.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  50%|█████     | 5/10 [07:57<08:17, 99.42s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  50%|█████     | 5/10 [08:03<08:23, 100.74s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  50%|█████     | 5/10 [08:07<08:27, 101.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  60%|██████    | 6/10 [09:50<06:54, 103.61s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  60%|██████    | 6/10 [09:58<06:59, 104.89s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  60%|██████    | 6/10 [10:02<07:02, 105.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  70%|███████   | 7/10 [11:43<05:19, 106.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  70%|███████   | 7/10 [11:52<05:22, 107.65s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  70%|███████   | 7/10 [11:57<05:24, 108.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  80%|████████  | 8/10 [13:59<03:50, 115.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  80%|████████  | 8/10 [14:11<03:53, 116.90s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  80%|████████  | 8/10 [14:17<03:55, 117.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4):  90%|█████████ | 9/10 [15:56<01:55, 115.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2):  90%|█████████ | 9/10 [16:09<01:57, 117.45s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 1):  90%|█████████ | 9/10 [16:16<01:58, 118.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 10/10 [17:49<00:00, 114.94s/it]\u001b[A\u001b[A\u001b[A\n",
      "Generating walks (CPU: 2): 100%|██████████| 10/10 [18:05<00:00, 116.79s/it]\u001b[A\n",
      "\n",
      "Generating walks (CPU: 4): 100%|██████████| 10/10 [19:44<00:00, 118.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating walks (CPU: 2): 100%|██████████| 10/10 [19:58<00:00, 119.84s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 10/10 [20:00<00:00, 120.02s/it]\n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [20:01<00:00, 120.15s/it]\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIMS = [64]\n",
    "WALK_LENGTHS = [40]\n",
    "NUM_WALKS = [10]\n",
    "WORKERS = [4]\n",
    "Ps = [1]\n",
    "Qs = [0.2, 2]\n",
    "\n",
    "for EMBEDDING_DIM in EMBEDDING_DIMS:\n",
    "    for WALK_LENGTH in WALK_LENGTHS:\n",
    "        for NUM_WALK in NUM_WALKS:\n",
    "            for WORKER in WORKERS:\n",
    "                for P in Ps:\n",
    "                    for Q in Qs:\n",
    "                        filename = \"ppi_node2vec_full_embeddings_\"+str(EMBEDDING_DIM)+\"_\"+str(WALK_LENGTH)+\"_\"+str(NUM_WALK)+\"_\"+str(P)+\"_\"+str(Q)+\".emb\"\n",
    "                        print(filename)\n",
    "                        if not Path(filename).is_file():\n",
    "                            node2vec = Node2Vec(G, dimensions=EMBEDDING_DIM, walk_length=WALK_LENGTH, num_walks=NUM_WALK, workers=WORKER, p = P, q = Q, temp_folder=\"tmp/\")\n",
    "                            model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "                            model.wv.save_word2vec_format(filename)\n",
    "                        \n",
    "                        data_emb = np.loadtxt(filename,skiprows=1)\n",
    "                        emb_dim = len(data_emb[0])-1\n",
    "                        num_nodes = len(list(G.nodes()))\n",
    "                        embedding = np.zeros((len(G.nodes()),emb_dim))\n",
    "                        for idx in range(data_emb.shape[0]):\n",
    "                            embedding[int(data_emb[idx][0])] = data_emb[idx][1:]\n",
    "                        X = np.zeros((num_nodes,emb_dim))\n",
    "                        idx = 0\n",
    "                        for node in G.nodes():\n",
    "                            X[idx] = embedding[node]\n",
    "                            idx += 1\n",
    "\n",
    "                        y = target\n",
    "                        s = np.arange(X.shape[0])\n",
    "                        np.random.shuffle(s)\n",
    "                        X2 = X[s]\n",
    "                        y2 = y[s]\n",
    "                        roc = []\n",
    "                        prec = []\n",
    "                        rec = []\n",
    "                        f1 = []\n",
    "                        kf = KFold(n_splits=5)\n",
    "                        for train_index, test_index in kf.split(X2):\n",
    "                            X_train2, X_test2 = X2[train_index], X2[test_index]\n",
    "                            y_train2, y_test2 = y2[train_index], y2[test_index]\n",
    "                            #clf = MLPClassifier(verbose=1)\n",
    "                            #clf.fit(X_train2,y_train2)\n",
    "                            forest = RandomForestClassifier(random_state=1,verbose=1,n_estimators=10)\n",
    "                            clf = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "                            clf.fit(X_train2,y_train2)\n",
    "\n",
    "                            pred = clf.predict(X_test2)\n",
    "\n",
    "\n",
    "                            roc.append(roc_auc_score(y_test2,pred, average='micro'))\n",
    "                            prec.append(precision_score(y_test2,pred, average='micro'))\n",
    "                            rec.append(recall_score(y_test2,pred, average='micro'))\n",
    "                            f1.append(f1_score(y_test2,pred, average='micro'))\n",
    "\n",
    "                        result = str(EMBEDDING_DIM)+\",\"+str(WALK_LENGTH)+\",\"+str(NUM_WALK)+\",\"+str(P)+\",\"+str(Q)+\",\"+str(np.mean(roc))+\",\"+str(np.mean(prec))+\",\"+str(np.mean(rec))+\",\"+str(np.mean(f1))+\"\\n\"\n",
    "                        f= open(\"result_multiclass_ppi_node2vec.txt\",\"a+\")\n",
    "                        f.write(result)\n",
    "                        f.close()\n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
